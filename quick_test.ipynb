{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Quick Benchmark Test\n",
                "\n",
                "빠른 검증을 위한 최소 샘플 벤치마크"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import torch\n",
                "from transformers import AutoTokenizer\n",
                "\n",
                "current_dir = os.getcwd()\n",
                "if current_dir not in sys.path:\n",
                "    sys.path.append(current_dir)\n",
                "\n",
                "from modeling_llada import LLaDAModelLM\n",
                "from configuration_llada import LLaDAConfig\n",
                "import experiment_utils\n",
                "import decoding\n",
                "\n",
                "print(\"✅ Modules loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load model\n",
                "HF_MODEL_ID = \"GSAI-ML/LLaDA-8B-Base\"\n",
                "config = LLaDAConfig.from_pretrained(HF_MODEL_ID)\n",
                "model = LLaDAModelLM.from_pretrained(HF_MODEL_ID, config=config, torch_dtype=\"auto\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    model.cuda()\n",
                "model.eval()\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_ID)\n",
                "print(\"✅ Model loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick test with minimal samples\n",
                "print(\"Starting quick test (2 samples, 2 configurations)...\")\n",
                "\n",
                "results_df = experiment_utils.run_academic_benchmark(\n",
                "    model=model,\n",
                "    tokenizer=tokenizer,\n",
                "    thresholds=[0.05, 0.10],  # Only 2 configurations\n",
                "    samples=2,  # Only 2 samples\n",
                "    steps=32,  # Reduced steps\n",
                "    gen_length=32,  # Reduced length\n",
                "    block_length=32,\n",
                "    remask_budget=0.05,\n",
                "    alpha_decay=0.05\n",
                ")\n",
                "\n",
                "print(\"\\n✅ Test completed!\")\n",
                "print(f\"Results shape: {results_df.shape}\")\n",
                "print(\"\\nFirst few rows:\")\n",
                "print(results_df.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick analysis\n",
                "print(\"\\n=== Quick Summary ===\")\n",
                "summary = results_df.groupby('Threshold')[['Acc_Exp', 'PPL_Delta', 'Stability_Delta']].mean()\n",
                "print(summary)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}