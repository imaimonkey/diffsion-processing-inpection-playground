{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLaDA Benchmark Playground\n",
    "\n",
    "이 노트북은 **정량적 평가**를 위한 벤치마크 실험을 수행합니다.\n",
    "\n",
    "## 목적\n",
    "- Academic Benchmarks (GSM8K, MMLU)를 사용한 A/B 테스트\n",
    "- Baseline vs Experimental 샘플링 전략 비교\n",
    "- 메트릭: Accuracy, Perplexity, Stability, Survival Rate, Correction Efficacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Add current directory to path\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "# Import local modules\n",
    "from modeling_llada import LLaDAModelLM\n",
    "from configuration_llada import LLaDAConfig\n",
    "import experiment_utils\n",
    "import decoding\n",
    "\n",
    "print(\"Modules loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_MODEL_PATH = \"../Grok-1-LLaDA-8B\"\n",
    "HF_MODEL_ID = \"GSAI-ML/LLaDA-8B-Base\"\n",
    "\n",
    "model_path = HF_MODEL_ID\n",
    "if os.path.exists(LOCAL_MODEL_PATH):\n",
    "    model_path = LOCAL_MODEL_PATH\n",
    "    print(f\"Using local model: {model_path}\")\n",
    "else:\n",
    "    print(f\"Using HuggingFace model: {model_path}\")\n",
    "\n",
    "config = LLaDAConfig.from_pretrained(model_path)\n",
    "model = LLaDAModelLM.from_pretrained(model_path, config=config, torch_dtype=\"auto\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Academic Benchmark\n",
    "\n",
    "이 셀은 GSM8K와 MMLU 데이터셋을 사용하여 다양한 `alpha_decay` 값에 대한 벤치마크를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Configuration\n",
    "ALPHA_DECAY_VALUES = [0.03, 0.05, 0.07, 0.10]  # Temporal decay rates to test\n",
    "N_SAMPLES = 50  # Number of samples per task\n",
    "STEPS = 64\n",
    "GEN_LENGTH = 64\n",
    "BLOCK_LENGTH = 64\n",
    "REMASK_BUDGET = 0.05\n",
    "\n",
    "print(f\"Starting benchmark with {len(ALPHA_DECAY_VALUES)} configurations...\")\n",
    "print(f\"Alpha Decay Values: {ALPHA_DECAY_VALUES}\")\n",
    "print(f\"Samples per task: {N_SAMPLES}\")\n",
    "\n",
    "results_df = experiment_utils.run_academic_benchmark(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    thresholds=ALPHA_DECAY_VALUES,\n",
    "    samples=N_SAMPLES,\n",
    "    steps=STEPS,\n",
    "    gen_length=GEN_LENGTH,\n",
    "    block_length=BLOCK_LENGTH,\n",
    "    remask_budget=REMASK_BUDGET,\n",
    "    alpha_decay=0.05  # Default, will be overridden by thresholds\n",
    ")\n",
    "\n",
    "print(\"\\nBenchmark completed!\")\n",
    "print(f\"Total results: {len(results_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive analysis\n",
    "experiment_utils.analyze_icml_results(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV for further analysis\n",
    "output_file = \"benchmark_results.csv\"\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detailed Inspection (Optional)\n",
    "\n",
    "특정 케이스를 자세히 살펴보고 싶다면 아래 셀을 사용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for specific category or threshold\n",
    "print(\"\\n=== Math Task Results ===\")\n",
    "math_results = results_df[results_df['Category'] == 'math']\n",
    "print(math_results.groupby('Threshold')[['Acc_Exp', 'PPL_Delta', 'Stability_Delta']].mean())\n",
    "\n",
    "print(\"\\n=== Logic Task Results ===\")\n",
    "logic_results = results_df[results_df['Category'] == 'logic']\n",
    "print(logic_results.groupby('Threshold')[['Acc_Exp', 'PPL_Delta', 'Stability_Delta']].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
